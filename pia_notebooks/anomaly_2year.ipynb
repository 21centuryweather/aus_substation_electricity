{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e655623d-84c8-47d1-b45c-4bdc482d7f3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9eebc1a-d01c-4ed9-b3bc-91f5aaab92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/565/pv3484/aus_substation_electricity\n",
      "/home/565/pv3484/aus_substation_electricity\n"
     ]
    }
   ],
   "source": [
    "#This gets us into the right directory from home, in order to run the import python script from Mat\n",
    "\n",
    "#sys = system (module), gives information and control over python interpreter/terminal itself\n",
    "import sys\n",
    "sys.path.append(\"/home/565/pv3484/aus_substation_electricity\")\n",
    "\n",
    "#% is a magic command, special shortcut command that lets you control/interact with notebook environment (ie. gives control of terminal without writing full python code)\n",
    "%cd aus_substation_electricity/\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c26e178-902c-496e-8418-0161bd0d9bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing nsw substations for ['ausgrid'] from None to None\n",
      "ausgrid\n",
      "following columns in demand are not in info index:\n",
      "['MT_HU', 'SI_NO']\n",
      "removing these columns from demand\n",
      "number of substations in ausgrid substation info: 134\n",
      "number of substations in ausgrid substation data: 132\n",
      "following sites match selection criteria:\n",
      "               energy_asset          Name  Area  Dwellings  Persons  Residential  Commercial  Industrial  Primary Production  Education  \\\n",
      "ID                                                                                                                                        \n",
      "BLAKE         AG_BLAKEHURST    Blakehurst     7      10081    28521        0.850       0.005       0.021               0.000      0.022   \n",
      "PUNCH          AG_PUNCHBOWL     Punchbowl     9      17514    50395        0.826       0.048       0.038               0.000      0.025   \n",
      "MEADO         AG_MEADOWBANK    Meadowbank    15      22420    56948        0.825       0.023       0.015               0.000      0.036   \n",
      "MOSMA             AG_MOSMAN        Mosman    11      25967    52831        0.817       0.046       0.001               0.000      0.013   \n",
      "RIVER          AG_RIVERWOOD     Riverwood    10      12528    34547        0.813       0.018       0.042               0.000      0.035   \n",
      "...                     ...           ...   ...        ...      ...          ...         ...         ...                 ...        ...   \n",
      "WE_GO       AG_WEST GOSFORD  West Gosford   145      12481    28063        0.081       0.016       0.012               0.018      0.005   \n",
      "WYONG              AG_WYONG         Wyong   186       8572    23207        0.067       0.002       0.012               0.258      0.004   \n",
      "RUTHE      AG_RUTHERFORD 33    Rutherford   227       6315    16066        0.065       0.001       0.012               0.900      0.002   \n",
      "ROTHB  AG_ROTHBURY 132/11KV      Rothbury   225       5677    13091        0.043       0.001       0.005               0.588      0.001   \n",
      "MUSWE    AG_MUSWELLBROOK 33  Muswellbrook   294       2574     5703        0.037       0.001       0.001               0.671      0.000   \n",
      "\n",
      "       Hospital/Medical  Transport  Parkland  Water  Other  \n",
      "ID                                                          \n",
      "BLAKE             0.001      0.000     0.102  0.000  0.000  \n",
      "PUNCH             0.002      0.001     0.061  0.000  0.000  \n",
      "MEADO             0.014      0.006     0.082  0.000  0.000  \n",
      "MOSMA             0.001      0.000     0.123  0.000  0.000  \n",
      "RIVER             0.002      0.001     0.089  0.000  0.000  \n",
      "...                 ...        ...       ...    ...    ...  \n",
      "WE_GO             0.001      0.000     0.549  0.005  0.312  \n",
      "WYONG             0.001      0.000     0.226  0.001  0.430  \n",
      "RUTHE             0.000      0.000     0.008  0.000  0.012  \n",
      "ROTHB             0.000      0.000     0.252  0.004  0.106  \n",
      "MUSWE             0.000      0.000     0.003  0.000  0.285  \n",
      "\n",
      "[84 rows x 15 columns]\n",
      "removing negative values\n",
      "removing values outside of 5 standard deviations, within t2m bins\n",
      "removing constant values\n",
      "not filling gaps, set fill_gaps=True to enable\n",
      "\n",
      "substation info:\n",
      "                energy_asset          Name  Area  Dwellings  Persons  Residential  Commercial  Industrial  Primary Production  Education  \\\n",
      "BLAKE         AG_BLAKEHURST    Blakehurst     7      10081    28521        0.850       0.005       0.021               0.000      0.022   \n",
      "PUNCH          AG_PUNCHBOWL     Punchbowl     9      17514    50395        0.826       0.048       0.038               0.000      0.025   \n",
      "MEADO         AG_MEADOWBANK    Meadowbank    15      22420    56948        0.825       0.023       0.015               0.000      0.036   \n",
      "MOSMA             AG_MOSMAN        Mosman    11      25967    52831        0.817       0.046       0.001               0.000      0.013   \n",
      "RIVER          AG_RIVERWOOD     Riverwood    10      12528    34547        0.813       0.018       0.042               0.000      0.035   \n",
      "...                     ...           ...   ...        ...      ...          ...         ...         ...                 ...        ...   \n",
      "WE_GO       AG_WEST GOSFORD  West Gosford   145      12481    28063        0.081       0.016       0.012               0.018      0.005   \n",
      "WYONG              AG_WYONG         Wyong   186       8572    23207        0.067       0.002       0.012               0.258      0.004   \n",
      "RUTHE      AG_RUTHERFORD 33    Rutherford   227       6315    16066        0.065       0.001       0.012               0.900      0.002   \n",
      "ROTHB  AG_ROTHBURY 132/11KV      Rothbury   225       5677    13091        0.043       0.001       0.005               0.588      0.001   \n",
      "MUSWE    AG_MUSWELLBROOK 33  Muswellbrook   294       2574     5703        0.037       0.001       0.001               0.671      0.000   \n",
      "\n",
      "       Hospital/Medical  Transport  Parkland  Water  Other  \n",
      "BLAKE             0.001      0.000     0.102  0.000  0.000  \n",
      "PUNCH             0.002      0.001     0.061  0.000  0.000  \n",
      "MEADO             0.014      0.006     0.082  0.000  0.000  \n",
      "MOSMA             0.001      0.000     0.123  0.000  0.000  \n",
      "RIVER             0.002      0.001     0.089  0.000  0.000  \n",
      "...                 ...        ...       ...    ...    ...  \n",
      "WE_GO             0.001      0.000     0.549  0.005  0.312  \n",
      "WYONG             0.001      0.000     0.226  0.001  0.430  \n",
      "RUTHE             0.000      0.000     0.008  0.000  0.012  \n",
      "ROTHB             0.000      0.000     0.252  0.004  0.106  \n",
      "MUSWE             0.000      0.000     0.003  0.000  0.285  \n",
      "\n",
      "[84 rows x 15 columns]\n",
      "\n",
      "cleaned demand data:\n",
      "                         BLAKE     PUNCH     MEADO     MOSMA     RIVER     CA_CO     DU_HI     FI_DO     UMINA     CAMPS  ...     LISAR     BEROW  \\\n",
      "2004-01-01 00:00:00       NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "2004-01-01 00:30:00  11.77248       NaN  33.32921  26.86411  13.89570  23.07817  22.18987  15.14478  14.97165  28.97894  ...  14.80155  15.49202   \n",
      "2004-01-01 01:00:00  10.40756  20.70845  30.79541  24.53589  11.52604  21.82337  20.55462  13.54961  17.09998  25.91148  ...  16.72754  13.00451   \n",
      "2004-01-01 01:30:00   9.53552  19.09061  28.38565  22.76285   9.99050  20.53466  18.80529  12.44237  14.73313  23.68233  ...  14.94422  11.04744   \n",
      "2004-01-01 02:00:00   8.39808  17.51083  26.50744  21.38383   8.39808  19.38160  17.60738  11.37266  11.99934  21.56750  ...  13.16090   8.92574   \n",
      "...                       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...   \n",
      "2017-04-30 21:30:00   9.50533  13.82180  35.61976  33.87399  10.75536  25.34371  21.80803  15.83637   9.37035  30.63082  ...   9.25361   8.73960   \n",
      "2017-04-30 22:00:00   9.98991  14.41893  36.12732  32.34371  11.55271  24.67497  20.17243  15.53987  11.66049  32.37968  ...   8.90197  10.06916   \n",
      "2017-04-30 22:30:00   9.11393  13.64618  34.36899  29.54764  10.79080  23.69757  18.59323  14.42365  11.39826  30.29581  ...   8.29123   9.20052   \n",
      "2017-04-30 23:00:00   8.20067  13.57593  33.15447  26.69490   9.97573  21.99999  17.12683  13.58649  12.79682  28.99578  ...   7.90258   9.80325   \n",
      "2017-04-30 23:30:00   8.20067  12.82073  33.10009  25.56136  11.32236  21.50272  16.07403  13.01094  13.86322  27.74438  ...   8.08765  11.20371   \n",
      "\n",
      "                        HO_BA    SOMER    MORIS     WE_GO     WYONG     RUTHE    ROTHB    MUSWE  \n",
      "2004-01-01 00:00:00       NaN      NaN      NaN       NaN       NaN       NaN      NaN      NaN  \n",
      "2004-01-01 00:30:00  11.29188  6.80748      NaN  16.65575  12.23212   5.18215      NaN  9.24960  \n",
      "2004-01-01 01:00:00  11.47669  7.15043      NaN  18.55414  13.84397   4.32418      NaN  7.81060  \n",
      "2004-01-01 01:30:00  11.12555  6.22447      NaN  16.83484  12.07094   3.56669      NaN  6.56823  \n",
      "2004-01-01 02:00:00  11.36580  5.62432      NaN  15.15136  10.62028   3.10251      NaN  6.05148  \n",
      "...                       ...      ...      ...       ...       ...       ...      ...      ...  \n",
      "2017-04-30 21:30:00  20.42508  6.76418  8.41530  19.75649  12.67888  11.14904  3.50684  4.42018  \n",
      "2017-04-30 22:00:00  19.34812  6.92181  7.90817  20.08455  13.20490  10.71381  3.45734  4.09225  \n",
      "2017-04-30 22:30:00  19.84947  6.82811  7.39908  19.73826  12.71516  10.25265  3.06595  4.03755  \n",
      "2017-04-30 23:00:00  19.55237  6.97921  8.43125  20.15745  13.24118  10.72097  3.14304  4.11488  \n",
      "2017-04-30 23:30:00  18.84678  7.51658  8.15187  19.28262  12.60633  10.21719  2.98684  3.93480  \n",
      "\n",
      "[205655 rows x 84 columns]\n",
      "\n",
      "BoM obs:\n",
      "                       t2m  t2m_30max  t2m_30min t2m_bin\n",
      "2000-01-01 00:00:00  16.8        NaN        NaN   15-19\n",
      "2000-01-01 00:30:00  16.4       16.9       16.4   15-19\n",
      "2000-01-01 01:00:00  16.0       16.4       16.0   15-19\n",
      "2000-01-01 01:30:00  15.9       16.0       15.9   15-19\n",
      "2000-01-01 02:00:00  15.7       16.0       15.6   15-19\n",
      "...                   ...        ...        ...     ...\n",
      "2022-12-31 21:30:00  22.1       22.2       22.0   20-24\n",
      "2022-12-31 22:00:00  21.9       22.2       21.9   20-24\n",
      "2022-12-31 22:30:00  21.7       22.0       21.7   20-24\n",
      "2022-12-31 23:00:00  21.7       21.8       21.6   20-24\n",
      "2022-12-31 23:30:00  21.5       21.8       21.5   20-24\n",
      "\n",
      "[403248 rows x 4 columns]\n",
      "Varibles: demand, info, obs\n"
     ]
    }
   ],
   "source": [
    "#This section imports the substations that Mat put together\n",
    "\n",
    "%run /home/565/pv3484/aus_substation_electricity/import_substation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006e2e6-4ea1-4f7f-8605-f2e0150034ae",
   "metadata": {},
   "source": [
    "# Anomaly Demand Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c0c26-8142-4d92-b855-1e386e72cd82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Demand Anomalies\n",
    "- soft coded to produce demand anomaly plot for all substations around a public holiday\n",
    "- 30 +/- window\n",
    "- includes full name of substation and residential fraction\n",
    "- only creates anomalies of a single date (eg. Aus day 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc7d6fc1-71b1-4a27-89fb-3eb2f20a83ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_anomalies_by_holiday(demand, info, ref_date, holiday_name,\n",
    "                              base_folder=\"/home/aus_substation_electricity/figures/Demand anomalies\",\n",
    "                              window_days=30):\n",
    "    \"\"\"\n",
    "    Generate and save demand anomaly plots for all substations around a holiday.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    demand : pd.DataFrame\n",
    "        Time-indexed demand data (datetime index, substations as columns).\n",
    "    info : pd.DataFrame\n",
    "        Metadata table with substation info (must include 'Name', 'Residential', 'Population' if available).\n",
    "    ref_date : str or pd.Timestamp\n",
    "        Reference date for the holiday (e.g., '2008-01-26').\n",
    "    holiday_name : str\n",
    "        Name of the holiday (used for folder organization).\n",
    "    base_folder : str\n",
    "        Base folder where plots will be saved.\n",
    "    window_days : int\n",
    "        Number of days before/after the reference date to include in the window.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Step 1: Ensure datetime index ---\n",
    "    demand.index = pd.to_datetime(demand.index)\n",
    "\n",
    "    # --- Step 2: Resample to hourly demand ---\n",
    "    hourly = demand.resample(\"h\").mean()\n",
    "\n",
    "    # --- Step 3: Reference date ---\n",
    "    ref_date = pd.Timestamp(ref_date)\n",
    "\n",
    "    # --- Step 4: Define ±window around reference date ---\n",
    "    start = ref_date - pd.Timedelta(days=window_days)\n",
    "    end   = ref_date + pd.Timedelta(days=window_days)\n",
    "\n",
    "    # --- Step 5: Create holiday-specific folder ---\n",
    "    holiday_folder = os.path.join(base_folder, holiday_name)\n",
    "    os.makedirs(holiday_folder, exist_ok=True)\n",
    "\n",
    "    # --- Step 6: Loop through each substation ---\n",
    "    for substation in hourly.columns:\n",
    "        # Slice window\n",
    "        window = hourly.loc[start:end, [substation]].copy()\n",
    "\n",
    "        # Baseline (mean across window)\n",
    "        baseline_mean = window[substation].mean()\n",
    "        window[\"anomaly\"] = window[substation] - baseline_mean\n",
    "\n",
    "        # Metadata\n",
    "        full_name = info.loc[substation, \"Name\"]\n",
    "        fraction = info.loc[substation, \"Residential\"]\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(14,5))\n",
    "        plt.plot(window.index, window[\"anomaly\"], color=\"red\", linewidth=1.5,\n",
    "                 label=f\"{full_name} Anomaly\")\n",
    "        plt.axhline(0, color=\"black\", linewidth=1)\n",
    "        plt.axvline(ref_date, color=\"blue\", linestyle=\"--\", alpha=0.7,\n",
    "                    label=f\"Reference Date {ref_date.date()}\")\n",
    "        plt.grid(axis='y', linestyle='-', linewidth=0.5, color='gray', alpha=0.3)\n",
    "\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=3))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%d\"))\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        plt.title(f\"Demand Anomaly (±{window_days} days around {ref_date.date()})\\n\"\n",
    "                  f\"{full_name} (Residential: {fraction:.0%})\", fontsize=14)\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Electricity Demand Anomaly\")\n",
    "        plt.legend(title=\"Reference\", bbox_to_anchor=(1.02, 1), loc=\"upper left\", fontsize=\"small\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save\n",
    "        #filename = f\"{substation}_{ref_date.date()}_anomaly.png\"\n",
    "        #filepath = os.path.join(holiday_folder, filename)\n",
    "        #plt.savefig(filepath, dpi=300)\n",
    "        #plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63081ad4-2132-4c24-b121-eb93efb6f1de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Comparing demand anomalies on Australia day against januarary weekends\n",
    "- not the same 30 day +/- period\n",
    "- can only change substation and date intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba7d1172-b984-4f49-b37e-d24ac3182e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def compare_australia_day_vs_jan_weekends(demand, info, station, years):\n",
    "    \"\"\"\n",
    "    Compare demand anomalies on Australia Day vs. January weekends for a given year interval.\n",
    "    \"\"\"\n",
    "    demand.index = pd.to_datetime(demand.index)\n",
    "    hourly = demand[[station]].resample(\"h\").mean()\n",
    "\n",
    "    # Collect ±30-day windows around Australia Day for each year\n",
    "    windows = []\n",
    "    for year in years:\n",
    "        ref_date = pd.Timestamp(f\"{year}-01-26\")\n",
    "        start = ref_date - pd.Timedelta(days=30)\n",
    "        end   = ref_date + pd.Timedelta(days=30)\n",
    "        window = hourly.loc[start:end].copy()\n",
    "        window[\"mdh\"] = window.index.strftime(\"%m-%d %H:%M\")\n",
    "        window = window.set_index(\"mdh\")\n",
    "        windows.append(window)\n",
    "\n",
    "    combined = pd.concat(windows, axis=1)\n",
    "    baseline_mean = combined.mean(axis=1).mean()\n",
    "    anomalies = combined.subtract(baseline_mean, axis=0)\n",
    "    avg_anomaly = anomalies.mean(axis=1)\n",
    "\n",
    "    # Australia Day anomalies (24 hours)\n",
    "    ad_hours = []\n",
    "    for year in years:\n",
    "        ref_date = pd.Timestamp(f\"{year}-01-26\")\n",
    "        day_str = ref_date.strftime(\"%m-%d\")\n",
    "        daily = avg_anomaly.loc[avg_anomaly.index.str.startswith(day_str)]\n",
    "        daily.index = range(24)\n",
    "        ad_hours.append(daily)\n",
    "    australia_day = pd.concat(ad_hours, axis=1).mean(axis=1)\n",
    "\n",
    "    # January weekend anomalies (24 hours)\n",
    "    weekend_hours = []\n",
    "    for year in years:\n",
    "        jan = hourly.loc[f\"{year}-01-01\":f\"{year}-01-31\"].copy()\n",
    "        jan_anomaly = jan.subtract(baseline_mean)\n",
    "        for day in pd.date_range(f\"{year}-01-01\", f\"{year}-01-31\"):\n",
    "            if day.weekday() >= 5:  # Sat=5, Sun=6\n",
    "                start = day.replace(hour=0, minute=0)\n",
    "                end   = day.replace(hour=23, minute=59)\n",
    "                daily = jan_anomaly.loc[start:end, station]\n",
    "                if not daily.empty:\n",
    "                    daily.index = daily.index.hour\n",
    "                    weekend_hours.append(daily)\n",
    "    weekends = pd.concat(weekend_hours, axis=1).mean(axis=1)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(australia_day.index, australia_day.values, color=\"red\", linewidth=2, marker=\"o\",\n",
    "             label=\"Australia Day Anomaly\")\n",
    "    plt.plot(weekends.index, weekends.values, color=\"blue\", linewidth=2, marker=\"s\",\n",
    "             label=\"January Weekends Anomaly\")\n",
    "\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "    plt.grid(axis='y', linestyle='-', linewidth=0.5, color='gray', alpha=0.3)\n",
    "    plt.xticks(np.arange(0, 24, 1), [f\"{h:02d}:00\" for h in range(24)], rotation=45)\n",
    "\n",
    "    full_name = info.loc[station, \"Name\"]\n",
    "    plt.title(f\"{full_name} Demand Anomaly: Australia Day vs. January Weekends ({years[0]}–{years[-1]})\", fontsize=14)\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Electricity Demand Anomaly\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "# --- Loop through consecutive intervals ---\n",
    "station = \"BLAKE\"\n",
    "year_range = range(2004, 2019)  # 2004–2018 inclusive\n",
    "\n",
    "for y1, y2 in zip(year_range[:-1], year_range[1:]):\n",
    "    compare_australia_day_vs_jan_weekends(demand, info, station, [y1, y2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41785cc8-f45b-48a6-bfb3-e4a1a4627bc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Australia Day Anomalies across 2 year periods\n",
    "- not soft coded, has a focus date and year interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f039916-e000-4187-9a03-e5409b164e44",
   "metadata": {},
   "source": [
    "### 2005-2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e2f438-5851-45cc-b75a-93f0c0684bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# --- Step 1: Ensure datetime index ---\n",
    "demand.index = pd.to_datetime(demand.index)\n",
    "\n",
    "# --- Step 2: Choose focus date and years ---\n",
    "focus_date = \"01-26\"   # e.g. Australia Day, change to \"12-25\" for Christmas\n",
    "years = [2005, 2006]   # list of years to average\n",
    "\n",
    "# --- Step 3: Resample to hourly demand ---\n",
    "hourly = demand.resample(\"h\").mean()\n",
    "\n",
    "# --- Step 4: Loop through each substation ---\n",
    "for station in hourly.columns:\n",
    "    # Collect ±30-day windows for each year\n",
    "    windows = []\n",
    "    for year in years:\n",
    "        ref_date = pd.Timestamp(f\"{year}-{focus_date}\")\n",
    "        start = ref_date - pd.Timedelta(days=30)\n",
    "        end   = ref_date + pd.Timedelta(days=30)\n",
    "        window = hourly.loc[start:end, [station]].copy()\n",
    "        window[\"mdh\"] = window.index.strftime(\"%m-%d %H:%M\")  # align by calendar date\n",
    "        window = window.set_index(\"mdh\")\n",
    "        windows.append(window)\n",
    "\n",
    "    # Combine all windows\n",
    "    combined = pd.concat(windows, axis=1)\n",
    "\n",
    "    # Compute baseline (mean demand across all years' windows)\n",
    "    baseline_mean = combined.mean(axis=1).mean()\n",
    "\n",
    "    # Compute anomalies for each year relative to baseline\n",
    "    anomalies = combined.subtract(baseline_mean, axis=0)\n",
    "\n",
    "    # Average anomalies across all chosen years\n",
    "    avg_anomaly = anomalies.mean(axis=1)\n",
    "\n",
    "    # Build datetime index for plotting (use first year for calendar axis)\n",
    "    ref_date = pd.Timestamp(f\"{years[0]}-{focus_date}\")\n",
    "    plot_index = pd.date_range(ref_date - pd.Timedelta(days=30),\n",
    "                               ref_date + pd.Timedelta(days=30),\n",
    "                               freq=\"h\")\n",
    "\n",
    "    # Get full substation name from metadata\n",
    "    full_name = info.loc[station, \"Name\"]\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.plot(plot_index, avg_anomaly.values, color=\"red\", linewidth=1.5,\n",
    "             label=f\"Average Anomaly ({years[0]}–{years[-1]})\")\n",
    "\n",
    "    # Baseline at 0\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "    # Mark focus date\n",
    "    plt.axvline(ref_date, color=\"blue\", linestyle=\"--\", alpha=0.7,\n",
    "                label=f\"Focus Date {focus_date}\")\n",
    "\n",
    "    # Grid and ticks\n",
    "    plt.grid(axis='y', linestyle='-', linewidth=0.5, color='gray', alpha=0.3)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=3))   # tick every 3 days\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%d\"))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Title with full substation name\n",
    "    plt.title(f\"{full_name} Average Demand Anomaly (±30 days around {focus_date}, {years[0]}–{years[-1]})\",\n",
    "              fontsize=14)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Electricity Demand Anomaly\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5c0c3-b768-433f-aef5-dbbeaee1c81e",
   "metadata": {},
   "source": [
    "### 2006-2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715a1b66-9f0f-438b-aff5-be25a1e0e26a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# --- Step 1: Ensure datetime index ---\n",
    "demand.index = pd.to_datetime(demand.index)\n",
    "\n",
    "# --- Step 2: Choose focus date and years ---\n",
    "focus_date = \"01-26\"   # e.g. Australia Day, change to \"12-25\" for Christmas\n",
    "years = [2015, 2016]   # list of years to average\n",
    "\n",
    "# --- Step 3: Resample to hourly demand ---\n",
    "hourly = demand.resample(\"h\").mean()\n",
    "\n",
    "# --- Step 4: Loop through each substation ---\n",
    "for station in hourly.columns:\n",
    "    # Collect ±30-day windows for each year\n",
    "    windows = []\n",
    "    for year in years:\n",
    "        ref_date = pd.Timestamp(f\"{year}-{focus_date}\")\n",
    "        start = ref_date - pd.Timedelta(days=30)\n",
    "        end   = ref_date + pd.Timedelta(days=30)\n",
    "        window = hourly.loc[start:end, [station]].copy()\n",
    "        window[\"mdh\"] = window.index.strftime(\"%m-%d %H:%M\")  # align by calendar date\n",
    "        window = window.set_index(\"mdh\")\n",
    "        windows.append(window)\n",
    "\n",
    "    # Combine all windows\n",
    "    combined = pd.concat(windows, axis=1)\n",
    "\n",
    "    # Compute baseline (mean demand across all years' windows)\n",
    "    baseline_mean = combined.mean(axis=1).mean()\n",
    "\n",
    "    # Compute anomalies for each year relative to baseline\n",
    "    anomalies = combined.subtract(baseline_mean, axis=0)\n",
    "\n",
    "    # Average anomalies across all chosen years\n",
    "    avg_anomaly = anomalies.mean(axis=1)\n",
    "\n",
    "    # Build datetime index for plotting (use first year for calendar axis)\n",
    "    ref_date = pd.Timestamp(f\"{years[0]}-{focus_date}\")\n",
    "    plot_index = pd.date_range(ref_date - pd.Timedelta(days=30),\n",
    "                               ref_date + pd.Timedelta(days=30),\n",
    "                               freq=\"h\")\n",
    "\n",
    "    # Get full substation name from metadata\n",
    "    full_name = info.loc[station, \"Name\"]\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.plot(plot_index, avg_anomaly.values, color=\"red\", linewidth=1.5,\n",
    "             label=f\"Average Anomaly ({years[0]}–{years[-1]})\")\n",
    "\n",
    "    # Baseline at 0\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "    # Mark focus date\n",
    "    plt.axvline(ref_date, color=\"blue\", linestyle=\"--\", alpha=0.7,\n",
    "                label=f\"Focus Date {focus_date}\")\n",
    "\n",
    "    # Grid and ticks\n",
    "    plt.grid(axis='y', linestyle='-', linewidth=0.5, color='gray', alpha=0.3)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=3))   # tick every 3 days\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%d\"))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Title with full substation name\n",
    "    plt.title(f\"{full_name} Average Demand Anomaly (±30 days around {focus_date}, {years[0]}–{years[-1]})\",\n",
    "              fontsize=14)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Electricity Demand Anomaly\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb2023-ba2e-420c-9e74-17b71f0e8c4a",
   "metadata": {},
   "source": [
    "### 2012 - 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53773d4c-1c43-4e94-b400-1af2a520b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# --- Step 1: Ensure datetime index ---\n",
    "demand.index = pd.to_datetime(demand.index)\n",
    "\n",
    "# --- Step 2: Choose focus date and years ---\n",
    "focus_date = \"01-26\"   # e.g. Australia Day, change to \"12-25\" for Christmas\n",
    "years = [2015, 2016]   # list of years to average\n",
    "\n",
    "# --- Step 3: Resample to hourly demand ---\n",
    "hourly = demand.resample(\"h\").mean()\n",
    "\n",
    "# --- Step 4: Loop through each substation ---\n",
    "for station in hourly.columns:\n",
    "    # Collect ±30-day windows for each year\n",
    "    windows = []\n",
    "    for year in years:\n",
    "        ref_date = pd.Timestamp(f\"{year}-{focus_date}\")\n",
    "        start = ref_date - pd.Timedelta(days=30)\n",
    "        end   = ref_date + pd.Timedelta(days=30)\n",
    "        window = hourly.loc[start:end, [station]].copy()\n",
    "        window[\"mdh\"] = window.index.strftime(\"%m-%d %H:%M\")  # align by calendar date\n",
    "        window = window.set_index(\"mdh\")\n",
    "        windows.append(window)\n",
    "\n",
    "    # Combine all windows\n",
    "    combined = pd.concat(windows, axis=1)\n",
    "\n",
    "    # Compute baseline (mean demand across all years' windows)\n",
    "    baseline_mean = combined.mean(axis=1).mean()\n",
    "\n",
    "    # Compute anomalies for each year relative to baseline\n",
    "    anomalies = combined.subtract(baseline_mean, axis=0)\n",
    "\n",
    "    # Average anomalies across all chosen years\n",
    "    avg_anomaly = anomalies.mean(axis=1)\n",
    "\n",
    "    # Build datetime index for plotting (use first year for calendar axis)\n",
    "    ref_date = pd.Timestamp(f\"{years[0]}-{focus_date}\")\n",
    "    plot_index = pd.date_range(ref_date - pd.Timedelta(days=30),\n",
    "                               ref_date + pd.Timedelta(days=30),\n",
    "                               freq=\"h\")\n",
    "\n",
    "    # Get full substation name from metadata\n",
    "    full_name = info.loc[station, \"Name\"]\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.plot(plot_index, avg_anomaly.values, color=\"red\", linewidth=1.5,\n",
    "             label=f\"Average Anomaly ({years[0]}–{years[-1]})\")\n",
    "\n",
    "    # Baseline at 0\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "    # Mark focus date\n",
    "    plt.axvline(ref_date, color=\"blue\", linestyle=\"--\", alpha=0.7,\n",
    "                label=f\"Focus Date {focus_date}\")\n",
    "\n",
    "    # Grid and ticks\n",
    "    plt.grid(axis='y', linestyle='-', linewidth=0.5, color='gray', alpha=0.3)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=3))   # tick every 3 days\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%d\"))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Title with full substation name\n",
    "    plt.title(f\"{full_name} Average Demand Anomaly (±30 days around {focus_date}, {years[0]}–{years[-1]})\",\n",
    "              fontsize=14)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Electricity Demand Anomaly\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbaa602-7d8c-46e8-87f3-876834f2e2cb",
   "metadata": {},
   "source": [
    "# Comparing weekend, weekday and pub holiday anomalies\n",
    "- soft coding the station, year intervals, public holiday (will ensure 30 days +/- will be around the chosen public holiday)\n",
    "- comparing the weekend, week-day and public holiday demand anomalies within the same 30 day +/- window period\n",
    "- accounts for moving holidays (eg. good friday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbdb7d8f-0806-4b3e-9432-10640fea2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dateutil.easter import easter\n",
    "import os\n",
    "\n",
    "def compare_holiday_weekends_weekdays_window(\n",
    "    demand, info, station, years, holiday_func, holiday_name,\n",
    "    output_dir=\"/home/565/pv3484/aus_substation_electricity/figures/anomaly_demand\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare demand anomalies on a holiday vs. weekends and weekdays\n",
    "    within the same ±30-day window around the holiday.\n",
    "    Saves plots as PNG files into holiday-specific folders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    demand : pd.DataFrame\n",
    "        Time-indexed demand data (datetime index, substations as columns).\n",
    "    info : pd.DataFrame\n",
    "        Metadata table with substation info (must include 'Name').\n",
    "    station : str\n",
    "        Substation ID (must match a column in demand and index in info).\n",
    "    years : list of int\n",
    "        Years to compare (e.g., [2005, 2006]).\n",
    "    holiday_func : callable\n",
    "        Function that returns the holiday date for a given year (e.g., easter).\n",
    "    holiday_name : str\n",
    "        Name of the holiday (used for folder organization).\n",
    "    output_dir : str\n",
    "        Base folder where plots will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure datetime index\n",
    "    demand.index = pd.to_datetime(demand.index)\n",
    "    hourly = demand[[station]].resample(\"h\").mean()\n",
    "\n",
    "    # Collect ±30-day windows around the holiday\n",
    "    windows = []\n",
    "    for year in years:\n",
    "        ref_date = holiday_func(year)\n",
    "        start = ref_date - pd.Timedelta(days=30)\n",
    "        end   = ref_date + pd.Timedelta(days=30)\n",
    "        window = hourly.loc[start:end].copy()\n",
    "        window[\"mdh\"] = window.index.strftime(\"%m-%d %H:%M\")\n",
    "        window = window.set_index(\"mdh\")\n",
    "        windows.append(window)\n",
    "\n",
    "    combined = pd.concat(windows, axis=1)\n",
    "    baseline_mean = combined.mean(axis=1).mean()\n",
    "    anomalies = combined.subtract(baseline_mean, axis=0)\n",
    "    avg_anomaly = anomalies.mean(axis=1)\n",
    "\n",
    "    # Holiday anomalies (24 hours)\n",
    "    holiday_hours = []\n",
    "    for year in years:\n",
    "        ref_date = holiday_func(year)\n",
    "        day_str = ref_date.strftime(\"%m-%d\")\n",
    "        daily = avg_anomaly.loc[avg_anomaly.index.str.startswith(day_str)]\n",
    "        if not daily.empty:\n",
    "            # Ensure exactly 24 hours, fill missing with NaN\n",
    "            daily = daily.reindex(range(24))\n",
    "            holiday_hours.append(daily)\n",
    "    if holiday_hours:\n",
    "        holiday_profile = pd.concat(holiday_hours, axis=1).mean(axis=1)\n",
    "    else:\n",
    "        holiday_profile = pd.Series(np.zeros(24), index=range(24))\n",
    "\n",
    "    # Weekend and weekday anomalies within the same ±30-day window\n",
    "    weekend_hours = []\n",
    "    weekday_hours = []\n",
    "    for year in years:\n",
    "        ref_date = holiday_func(year)\n",
    "        start = ref_date - pd.Timedelta(days=30)\n",
    "        end   = ref_date + pd.Timedelta(days=30)\n",
    "        window = hourly.loc[start:end].copy()\n",
    "        window_anomaly = window.subtract(baseline_mean)\n",
    "        for day in pd.date_range(start, end):\n",
    "            start_day = day.replace(hour=0, minute=0)\n",
    "            end_day   = day.replace(hour=23, minute=59)\n",
    "            daily = window_anomaly.loc[start_day:end_day, station]\n",
    "            if not daily.empty:\n",
    "                daily.index = daily.index.hour\n",
    "                if day.weekday() >= 5:  # Sat=5, Sun=6\n",
    "                    weekend_hours.append(daily)\n",
    "                else:\n",
    "                    weekday_hours.append(daily)\n",
    "    weekend_profile = pd.concat(weekend_hours, axis=1).mean(axis=1) if weekend_hours else pd.Series(np.zeros(24), index=range(24))\n",
    "    weekday_profile = pd.concat(weekday_hours, axis=1).mean(axis=1) if weekday_hours else pd.Series(np.zeros(24), index=range(24))\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(holiday_profile.index, holiday_profile.values, color=\"red\", linewidth=2, marker=\"o\",\n",
    "             label=f\"{holiday_name} (±30-Day Window)\")\n",
    "    if not weekend_profile.empty:\n",
    "        plt.plot(weekend_profile.index, weekend_profile.values, color=\"blue\", linewidth=2, marker=\"s\",\n",
    "                 label=\"Weekends (±30-Day Window)\")\n",
    "    if not weekday_profile.empty:\n",
    "        plt.plot(weekday_profile.index, weekday_profile.values, color=\"green\", linewidth=2, marker=\"^\",\n",
    "                 label=\"Weekdays (±30-Day Window)\")\n",
    "\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "    plt.grid(axis='y', linestyle='-', linewidth=0.5, color='gray', alpha=0.3)\n",
    "    plt.xticks(np.arange(0, 24, 1), [f\"{h:02d}:00\" for h in range(24)], rotation=45)\n",
    "\n",
    "    full_name = info.loc[station, \"Name\"]\n",
    "    plt.title(\n",
    "        f\"{full_name} Demand Anomaly: {holiday_name} vs. Weekends & Weekdays \"\n",
    "        f\"(±30-Day Window, {years[0]}–{years[-1]})\",\n",
    "        fontsize=14\n",
    "    )\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Electricity Demand Anomaly\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Save instead of show ---\n",
    "    # Holiday-specific folder (no year interval in folder name)\n",
    "    holiday_folder = os.path.join(output_dir, holiday_name)\n",
    "    os.makedirs(holiday_folder, exist_ok=True)\n",
    "\n",
    "    filename = f\"{station}_{years[0]}-{years[-1]}.png\"\n",
    "    filepath = os.path.join(holiday_folder, filename)\n",
    "\n",
    "    plt.savefig(filepath, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef2a7c-6959-4ce0-beb2-c6fef263abe0",
   "metadata": {},
   "source": [
    "## Using the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ea454ba-0a8e-41e0-9996-e04a1f6f84d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the station\n",
    "station = \"BLAKE\"\n",
    "\n",
    "# Define the year intervals you want to loop through\n",
    "intervals = [\n",
    "    [2004, 2005],\n",
    "    [2007, 2008],\n",
    "    [2014, 2015],\n",
    "    [2017, 2018], #Christmas and Boxing Day do not have data for 2017-2018\n",
    "]\n",
    "\n",
    "# Define the all national public holidays (including moving i.e. easter, is accounted for)\n",
    "holidays = {\n",
    "    \"New Year's Day\": lambda y: pd.Timestamp(f\"{y}-01-01\"),\n",
    "    \"Australia Day\": lambda y: pd.Timestamp(f\"{y}-01-26\"),\n",
    "    \"Good Friday\": lambda y: easter(y) - pd.Timedelta(days=2),\n",
    "    \"Easter Saturday\": lambda y: easter(y) - pd.Timedelta(days=1),\n",
    "    \"Easter Sunday\": lambda y: easter(y),\n",
    "    \"Easter Monday\": lambda y: easter(y) + pd.Timedelta(days=1),\n",
    "    \"ANZAC Day\": lambda y: pd.Timestamp(f\"{y}-04-25\"),\n",
    "    \"Christmas Day\": lambda y: pd.Timestamp(f\"{y}-12-25\"),\n",
    "    \"Boxing Day\": lambda y: pd.Timestamp(f\"{y}-12-26\"),\n",
    "}\n",
    "\n",
    "# Loop through intervals and holidays\n",
    "for years in intervals:\n",
    "    for holiday_name, holiday_func in holidays.items():\n",
    "        compare_holiday_weekends_weekdays_window(\n",
    "            demand, info, station, years,\n",
    "            holiday_func=holiday_func,\n",
    "            holiday_name=holiday_name\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-25.10] *",
   "language": "python",
   "name": "conda-env-analysis3-25.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
